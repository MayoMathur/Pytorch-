{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 73.,  67.,  43.],\n",
       "        [ 91.,  88.,  64.],\n",
       "        [ 87., 134.,  58.],\n",
       "        [102.,  43.,  37.],\n",
       "        [ 69.,  96.,  70.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs temperature, rainfall, humidity\n",
    "inputs = np.array([[73, 67, 43],[91, 88, 64],[87, 134,58],[102, 43,37],[69,96,70]], dtype='float32')\n",
    "print(inputs.size)\n",
    "inpt = torch.from_numpy(inputs)\n",
    "inpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apples, oranges\n",
    "targets = np.array([[56,70], [81,101], [119,133], [22,37], [103,119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3757, -1.3237,  0.4534],\n",
      "        [ 0.1642, -0.7022,  0.2615]], requires_grad=True)\n",
      "tensor([2.4079, 0.5795], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w = torch.randn((2, 3), requires_grad=True)\n",
    "b  = torch.randn(2, requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " def model(x):\n",
    "        return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -94.2127,  -23.2412],\n",
      "        [-119.2523,  -29.5418],\n",
      "        [-181.3609,  -64.0707],\n",
      "        [ -76.0601,   -3.1948],\n",
      "        [-118.8556,  -37.2030]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#  Generate Predictions\n",
    "predict = model(inpt)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 56.  70.]\n",
      " [ 81. 101.]\n",
      " [119. 133.]\n",
      " [ 22.  37.]\n",
      " [103. 119.]]\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Compare with targets \n",
    "print(targets)\n",
    "target = torch.from_numpy(targets)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-150.2127,  -93.2412],\n",
      "        [-200.2523, -130.5418],\n",
      "        [-300.3609, -197.0707],\n",
      "        [ -98.0601,  -40.1948],\n",
      "        [-221.8556, -156.2030]], grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(30230.4160, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate to check how well the model works by calculating the difference in predict and target\n",
    "\n",
    "diff = ( predict - target) #element wise subtraction\n",
    "print(diff) \n",
    "torch.sum(diff * diff)/ diff.numel()# normal multiplication and not matrix multiplication\n",
    "# Above we have calculated loss function using Mean Square Error\n",
    "# First - calculate diffrence between two matrices (predict and target)\n",
    "# Second - Calculate square of each element to remove negative values\n",
    "# Third - Average of all elements of the resultant amtrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(30230.4160, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Using above create loss function\n",
    "# Loss is function of weights as we change weights the loss also changes\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff*diff)/diff.numel()\n",
    "\n",
    "loss = mse(predict, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173.86896215253603"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 30230.4160\n",
    "math.sqrt(x)\n",
    "# Difference of preidction is lying between 50-200 which makes the model bad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3757, -1.3237,  0.4534],\n",
      "        [ 0.1642, -0.7022,  0.2615]], requires_grad=True)\n",
      "tensor([[-16126.0107, -18689.9102, -11170.8691],\n",
      "        [-10141.7871, -12173.2363,  -7243.1133]])\n"
     ]
    }
   ],
   "source": [
    "# To improve the model we will use gradient descent\n",
    "loss.backward()\n",
    "\n",
    "# Compute partial derivative of weight  which ets stored in .grad \n",
    "print(w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Gradient indicates the rate of change of loss i.e. slope of the loss function w.r.t. weights and biases\n",
    "if gradient is positive \n",
    " increasing element value will increase loss and vice versa.\n",
    "if gradient is negative \n",
    "    increasing element value will decrease loss and vice versa. \n",
    "this will form basis for optimization algorithm used for improving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Use .zero_() to reset the gradients. To avoid new gradients to get added along with existing gradients which can lead to different result\n",
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# even after removing grad both have same values\n",
    "#w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization algorithm by adjusting weight and biases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 59.5357,  72.7002],\n",
      "        [ 86.8308, 101.4836],\n",
      "        [104.3734, 127.2662],\n",
      "        [ 32.8194,  50.2676],\n",
      "        [103.5903, 112.9339]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "predict = model(inpt)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(63.1073, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "loss = mse(predict, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 132.1001, -137.6123,   23.7000],\n",
      "        [ 135.4027, -111.3405,  -23.8459]])\n",
      "tensor([2.4598, 1.8606])\n"
     ]
    }
   ],
   "source": [
    "# Compute Gradients of weights and biases\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust weights by subtracting small quantity propotinal to gradient from it\n",
    "# Adjust and reset gradients\n",
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2951,  0.4952,  1.0575],\n",
      "        [-0.0719,  0.6566,  0.7758]], requires_grad=True)\n",
      "tensor([2.4120, 0.5807], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(62.4269, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# calculate loss\n",
    "predict = model(inpt)\n",
    "loss = mse(predict, target)\n",
    "print(loss)\n",
    "# Compare with previous loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for multiple epochs\n",
    "for i in range(150):\n",
    "    predict = model(inpt)\n",
    "    loss = mse(predict, target)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.5053, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "predict = model(inpt)\n",
    "loss = mse(predict, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 57.6368,  70.8044],\n",
       "        [ 84.5405, 100.2384],\n",
       "        [112.6350, 133.1458],\n",
       "        [ 21.6831,  39.2540],\n",
       "        [106.1042, 117.1945]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Targets \n",
    "target\n",
    "# predictions can be made close by increasing epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
